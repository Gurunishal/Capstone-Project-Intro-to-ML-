{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Name: Gurunishal Saravanan\n",
        "## Student ID: 801430631"
      ],
      "metadata": {
        "id": "hy4g4Aor92KF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method A"
      ],
      "metadata": {
        "id": "5DxN4y2-7aP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "train_data = np.loadtxt('/content/ECG5000_TRAIN.txt')\n",
        "test_data = np.loadtxt('/content/ECG5000_TEST.txt')\n",
        "\n",
        "X_train = train_data[:, 1:]\n",
        "y_train = train_data[:, 0] - 1\n",
        "\n",
        "X_test = test_data[:, 1:]\n",
        "y_test = test_data[:, 0] - 1\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(2)\n",
        "y_train = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(2)\n",
        "y_test = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "print(\"Train shape:\", X_train.shape)\n",
        "print(\"Test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-sSpP_R5vW9",
        "outputId": "f2b6a84f-8ff0-4e48-9ba2-b05c3b542a08"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: torch.Size([500, 140, 1])\n",
            "Test shape: torch.Size([4500, 140, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ECGDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "trn_dataset = ECGDataset(X_train, y_train)\n",
        "tst_dataset = ECGDataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(trn_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(tst_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "58479yPy5zo8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ECGCNN(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super(ECGCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(32, 64, 5, stride=1, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "        self.pool2 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "        self.pool3 = nn.MaxPool1d(2)\n",
        "\n",
        "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
        "        x = self.global_pool(x).squeeze(2)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "CJ3B1jEq52Vv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = ECGCNN().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * X_batch.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/total:.4f}, Accuracy: {correct/total:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0PrJTmG53kE",
        "outputId": "c03118d7-af02-466d-8b72-99608a0a78cc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.9871, Accuracy: 0.7860\n",
            "Epoch 2, Loss: 0.4439, Accuracy: 0.9080\n",
            "Epoch 3, Loss: 0.3510, Accuracy: 0.9160\n",
            "Epoch 4, Loss: 0.3092, Accuracy: 0.9280\n",
            "Epoch 5, Loss: 0.2676, Accuracy: 0.9360\n",
            "Epoch 6, Loss: 0.2464, Accuracy: 0.9360\n",
            "Epoch 7, Loss: 0.2236, Accuracy: 0.9380\n",
            "Epoch 8, Loss: 0.2148, Accuracy: 0.9340\n",
            "Epoch 9, Loss: 0.2029, Accuracy: 0.9400\n",
            "Epoch 10, Loss: 0.1945, Accuracy: 0.9440\n",
            "Epoch 11, Loss: 0.1715, Accuracy: 0.9500\n",
            "Epoch 12, Loss: 0.1653, Accuracy: 0.9600\n",
            "Epoch 13, Loss: 0.1577, Accuracy: 0.9540\n",
            "Epoch 14, Loss: 0.1505, Accuracy: 0.9580\n",
            "Epoch 15, Loss: 0.1456, Accuracy: 0.9580\n",
            "Epoch 16, Loss: 0.1310, Accuracy: 0.9620\n",
            "Epoch 17, Loss: 0.1442, Accuracy: 0.9600\n",
            "Epoch 18, Loss: 0.1338, Accuracy: 0.9580\n",
            "Epoch 19, Loss: 0.1278, Accuracy: 0.9620\n",
            "Epoch 20, Loss: 0.1118, Accuracy: 0.9680\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        outputs = model(X_batch)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        correct += (preds == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(y_batch.cpu().numpy())\n",
        "\n",
        "accuracy = correct / total\n",
        "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YhukEJC66Gs",
        "outputId": "7caf7a55-6090-4a96-f9b3-9f9460338e80"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9316\n",
            "F1 Score: 0.9263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method B"
      ],
      "metadata": {
        "id": "dy_M_5bZ7e7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def load_ecg5000(train_file, test_file):\n",
        "    train_data = np.loadtxt(train_file)\n",
        "    test_data = np.loadtxt(test_file)\n",
        "\n",
        "    X_train = train_data[:, 1:]\n",
        "    y_train = train_data[:, 0].astype(int)\n",
        "    X_test = test_data[:, 1:]\n",
        "    y_test = test_data[:, 0].astype(int)\n",
        "\n",
        "    X_train = X_train[..., np.newaxis]\n",
        "    X_test = X_test[..., np.newaxis]\n",
        "\n",
        "    y_train -= 1\n",
        "    y_test -= 1\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "X_train, y_train, X_test, y_test = load_ecg5000(\n",
        "    \"/content/ECG5000_TRAIN.txt\",\n",
        "    \"/content/ECG5000_TEST.txt\"\n",
        ")\n",
        "\n",
        "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WS74nnj6VIo1",
        "outputId": "19410eaf-c18d-43a9-8d21-343ee52d0703"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train shape: (500, 140, 1), Test shape: (4500, 140, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_fcn(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv1D(128, 8, padding='same', activation='relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv1D(256, 5, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def residual_block(x, filters, kernel_size=8, stride=1):\n",
        "    shortcut = x\n",
        "    x = layers.Conv1D(filters, kernel_size, strides=stride, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.Conv1D(filters, kernel_size, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    if shortcut.shape[-1] != filters:\n",
        "        shortcut = layers.Conv1D(filters, 1, padding='same')(shortcut)\n",
        "    x = layers.add([shortcut, x])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def build_resnet(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for filters in [64, 128, 128]:\n",
        "        x = residual_block(x, filters)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_encoder(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Conv1D(128, 5, padding='same', activation='relu')(inputs)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "    x = layers.Conv1D(256, 11, padding='same', activation='relu')(x)\n",
        "    x = layers.LayerNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def build_mlp(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = layers.Flatten()(inputs)\n",
        "    x = layers.Dense(500, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    x = layers.Dense(500, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "77T5ht9cVRGg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ensemble_predict(models, X):\n",
        "    preds = [np.argmax(m.predict(X), axis=1) for m in models]\n",
        "    preds = np.stack(preds, axis=1)\n",
        "    final_pred = np.array([Counter(row).most_common(1)[0][0] for row in preds])\n",
        "    return final_pred"
      ],
      "metadata": {
        "id": "sBFVe4teVTdO"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "num_classes = len(np.unique(y_train))\n",
        "\n",
        "models_list = [\n",
        "    build_fcn(input_shape, num_classes),\n",
        "    build_resnet(input_shape, num_classes),\n",
        "    build_encoder(input_shape, num_classes),\n",
        "    build_mlp(input_shape, num_classes)\n",
        "]\n",
        "\n",
        "for model in models_list:\n",
        "    print(f\"Training {model.name}...\")\n",
        "    model.fit(X_train, y_train, epochs=10, batch_size=64, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weEmALpIVVwJ",
        "outputId": "bbe77b65-2e55-4f52-f4f6-f9d827ddab39"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training functional_10...\n",
            "Epoch 1/10\n",
            "8/8 - 7s - 872ms/step - accuracy: 0.8340 - loss: 0.8310\n",
            "Epoch 2/10\n",
            "8/8 - 5s - 581ms/step - accuracy: 0.9040 - loss: 0.4721\n",
            "Epoch 3/10\n",
            "8/8 - 3s - 426ms/step - accuracy: 0.9220 - loss: 0.3734\n",
            "Epoch 4/10\n",
            "8/8 - 5s - 631ms/step - accuracy: 0.9320 - loss: 0.3035\n",
            "Epoch 5/10\n",
            "8/8 - 4s - 470ms/step - accuracy: 0.9340 - loss: 0.2611\n",
            "Epoch 6/10\n",
            "8/8 - 4s - 508ms/step - accuracy: 0.9440 - loss: 0.2207\n",
            "Epoch 7/10\n",
            "8/8 - 7s - 850ms/step - accuracy: 0.9420 - loss: 0.2137\n",
            "Epoch 8/10\n",
            "8/8 - 4s - 558ms/step - accuracy: 0.9500 - loss: 0.2008\n",
            "Epoch 9/10\n",
            "8/8 - 3s - 420ms/step - accuracy: 0.9460 - loss: 0.1935\n",
            "Epoch 10/10\n",
            "8/8 - 3s - 335ms/step - accuracy: 0.9540 - loss: 0.1781\n",
            "Training functional_11...\n",
            "Epoch 1/10\n",
            "8/8 - 13s - 2s/step - accuracy: 0.8320 - loss: 0.6958\n",
            "Epoch 2/10\n",
            "8/8 - 11s - 1s/step - accuracy: 0.9280 - loss: 0.2562\n",
            "Epoch 3/10\n",
            "8/8 - 10s - 1s/step - accuracy: 0.9380 - loss: 0.2180\n",
            "Epoch 4/10\n",
            "8/8 - 13s - 2s/step - accuracy: 0.9440 - loss: 0.1980\n",
            "Epoch 5/10\n",
            "8/8 - 9s - 1s/step - accuracy: 0.9520 - loss: 0.1674\n",
            "Epoch 6/10\n",
            "8/8 - 11s - 1s/step - accuracy: 0.9540 - loss: 0.1490\n",
            "Epoch 7/10\n",
            "8/8 - 7s - 839ms/step - accuracy: 0.9600 - loss: 0.1439\n",
            "Epoch 8/10\n",
            "8/8 - 10s - 1s/step - accuracy: 0.9660 - loss: 0.1306\n",
            "Epoch 9/10\n",
            "8/8 - 10s - 1s/step - accuracy: 0.9620 - loss: 0.1240\n",
            "Epoch 10/10\n",
            "8/8 - 10s - 1s/step - accuracy: 0.9600 - loss: 0.1216\n",
            "Training functional_12...\n",
            "Epoch 1/10\n",
            "8/8 - 6s - 715ms/step - accuracy: 0.6000 - loss: 1.1637\n",
            "Epoch 2/10\n",
            "8/8 - 4s - 559ms/step - accuracy: 0.8220 - loss: 0.7202\n",
            "Epoch 3/10\n",
            "8/8 - 4s - 530ms/step - accuracy: 0.8420 - loss: 0.6251\n",
            "Epoch 4/10\n",
            "8/8 - 4s - 455ms/step - accuracy: 0.8560 - loss: 0.5635\n",
            "Epoch 5/10\n",
            "8/8 - 6s - 800ms/step - accuracy: 0.8640 - loss: 0.5263\n",
            "Epoch 6/10\n",
            "8/8 - 5s - 568ms/step - accuracy: 0.8740 - loss: 0.5057\n",
            "Epoch 7/10\n",
            "8/8 - 4s - 449ms/step - accuracy: 0.8760 - loss: 0.4804\n",
            "Epoch 8/10\n",
            "8/8 - 6s - 796ms/step - accuracy: 0.8800 - loss: 0.4496\n",
            "Epoch 9/10\n",
            "8/8 - 4s - 452ms/step - accuracy: 0.8960 - loss: 0.4278\n",
            "Epoch 10/10\n",
            "8/8 - 4s - 453ms/step - accuracy: 0.8980 - loss: 0.4334\n",
            "Training functional_13...\n",
            "Epoch 1/10\n",
            "8/8 - 2s - 226ms/step - accuracy: 0.7920 - loss: 0.7176\n",
            "Epoch 2/10\n",
            "8/8 - 0s - 23ms/step - accuracy: 0.9300 - loss: 0.3396\n",
            "Epoch 3/10\n",
            "8/8 - 0s - 23ms/step - accuracy: 0.9300 - loss: 0.2653\n",
            "Epoch 4/10\n",
            "8/8 - 0s - 37ms/step - accuracy: 0.9420 - loss: 0.1993\n",
            "Epoch 5/10\n",
            "8/8 - 0s - 30ms/step - accuracy: 0.9500 - loss: 0.1899\n",
            "Epoch 6/10\n",
            "8/8 - 0s - 17ms/step - accuracy: 0.9520 - loss: 0.1595\n",
            "Epoch 7/10\n",
            "8/8 - 0s - 19ms/step - accuracy: 0.9460 - loss: 0.1444\n",
            "Epoch 8/10\n",
            "8/8 - 0s - 14ms/step - accuracy: 0.9540 - loss: 0.1541\n",
            "Epoch 9/10\n",
            "8/8 - 0s - 13ms/step - accuracy: 0.9600 - loss: 0.1310\n",
            "Epoch 10/10\n",
            "8/8 - 0s - 17ms/step - accuracy: 0.9620 - loss: 0.1298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "y_pred = ensemble_predict(models_list, X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Ensemble accuracy: {acc:.4f}\")\n",
        "print(f\"Ensemble F1-score (macro): {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrIi-e0dVdl2",
        "outputId": "d3756051-5621-4be8-e631-b6917a99b81a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 71ms/step\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 94ms/step\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 74ms/step\n",
            "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Ensemble accuracy: 0.9009\n",
            "Ensemble F1-score (macro): 0.8780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method C"
      ],
      "metadata": {
        "id": "3qCnMyfX9Iss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "train_data = np.loadtxt('/content/ECG5000_TRAIN.txt')\n",
        "test_data = np.loadtxt('/content/ECG5000_TEST.txt')\n",
        "\n",
        "X_train = train_data[:, 1:]\n",
        "y_train = train_data[:, 0] - 1\n",
        "\n",
        "X_test = test_data[:, 1:]\n",
        "y_test = test_data[:, 0] - 1\n",
        "\n",
        "# Initialize KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
        "\n",
        "# Train\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Compute F1-score (macro average)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# Print both\n",
        "print(f\"KNN Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"KNN F1-score (macro): {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJ73Ucy09Mep",
        "outputId": "782684db-0187-4592-a3ee-b179abe7c2e1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN Accuracy: 93.49%\n",
            "KNN F1-score (macro): 0.9264\n"
          ]
        }
      ]
    }
  ]
}